<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>性能分析调优 - Desk &amp; FS - 弓长笔记</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="jincheng9" /><meta name="description" content="磁盘和文件系统 机械硬盘 查看系统块设备文件列表： 1 2 3 4 5 6 7 8 $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 30G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 29G 0 part ├" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.101.0 with theme even" />


<link rel="canonical" href="http://blog.gongchang.me/post/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E8%B0%83%E4%BC%98-desk-fs/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="性能分析调优 - Desk &amp; FS" />
<meta property="og:description" content="磁盘和文件系统 机械硬盘 查看系统块设备文件列表： 1 2 3 4 5 6 7 8 $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 30G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 29G 0 part ├" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://blog.gongchang.me/post/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E8%B0%83%E4%BC%98-desk-fs/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-02-07T23:09:31+08:00" />
<meta property="article:modified_time" content="2022-02-07T23:09:31+08:00" />

<meta itemprop="name" content="性能分析调优 - Desk &amp; FS">
<meta itemprop="description" content="磁盘和文件系统 机械硬盘 查看系统块设备文件列表： 1 2 3 4 5 6 7 8 $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 30G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 29G 0 part ├"><meta itemprop="datePublished" content="2022-02-07T23:09:31+08:00" />
<meta itemprop="dateModified" content="2022-02-07T23:09:31+08:00" />
<meta itemprop="wordCount" content="6856">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="性能分析调优 - Desk &amp; FS"/>
<meta name="twitter:description" content="磁盘和文件系统 机械硬盘 查看系统块设备文件列表： 1 2 3 4 5 6 7 8 $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 30G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 29G 0 part ├"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">弓长笔记</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">全部文章</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">弓长笔记</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">全部文章</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">性能分析调优 - Desk &amp; FS</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-02-07 </span>
        
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#磁盘和文件系统">磁盘和文件系统</a>
      <ul>
        <li><a href="#机械硬盘">机械硬盘</a></li>
        <li><a href="#固态硬盘">固态硬盘</a></li>
        <li><a href="#文件系统结构">文件系统结构</a>
          <ul>
            <li><a href="#查看文件的基本存储单位-block-size">查看文件的基本存储单位 block size</a></li>
            <li><a href="#查看文件系统的-inode">查看文件系统的 inode</a></li>
            <li><a href="#什么是硬链接">什么是硬链接</a></li>
            <li><a href="#什么是软链接">什么是软链接</a></li>
          </ul>
        </li>
        <li><a href="#磁盘划分">磁盘划分</a></li>
        <li><a href="#冗余独立磁盘阵列raid">冗余独立磁盘阵列（RAID）</a></li>
      </ul>
    </li>
    <li><a href="#文件访问的鉴权过程">文件访问的鉴权过程</a></li>
    <li><a href="#浅析-linux-io-stack">浅析 Linux IO Stack</a>
      <ul>
        <li><a href="#应用层">应用层</a></li>
        <li><a href="#虚拟文件系统层-vfs">虚拟文件系统层 VFS</a></li>
        <li><a href="#page-cache">Page Cache</a></li>
        <li><a href="#文件系统层">文件系统层</a></li>
        <li><a href="#通用块管理层">通用块管理层</a></li>
        <li><a href="#io-调度层">IO 调度层</a></li>
      </ul>
    </li>
    <li><a href="#read-文件一个字节的io开销">read 文件一个字节的IO开销</a></li>
    <li><a href="#write-文件一个字节的io开销">write 文件一个字节的IO开销</a></li>
    <li><a href="#为什么有时候-ls-命令会卡住">为什么有时候 ls 命令会卡住？</a></li>
    <li><a href="#查看分析磁盘性能问题">查看分析磁盘性能问题</a>
      <ul>
        <li><a href="#系统级检查">系统级检查</a></li>
        <li><a href="#进程级检查">进程级检查</a></li>
      </ul>
    </li>
    <li><a href="#磁盘-io-优化建议">磁盘 IO 优化建议</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="磁盘和文件系统">磁盘和文件系统</h1>
<h2 id="机械硬盘">机械硬盘</h2>
<p><img src="/img/hdd_logic.png" alt=""></p>
<p>查看系统块设备文件列表：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ lsblk
</span></span><span class="line"><span class="cl">NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
</span></span><span class="line"><span class="cl">sda               8:0    0   30G  0 disk
</span></span><span class="line"><span class="cl">├─sda1            8:1    0    1G  0 part /boot
</span></span><span class="line"><span class="cl">└─sda2            8:2    0   29G  0 part
</span></span><span class="line"><span class="cl">  ├─centos-root 253:0    0   27G  0 lvm  /
</span></span><span class="line"><span class="cl">  └─centos-swap 253:1    0    2G  0 lvm
</span></span><span class="line"><span class="cl">sr0              11:0    1  4.4G  0 rom
</span></span></code></pre></td></tr></table>
</div>
</div><p>接下来再通过 fdisk 这个命令来查看硬盘更详细的信息：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ fdisk -l /dev/sda
</span></span><span class="line"><span class="cl">Disk /dev/sda: 299.0 GB, 298999349248 bytes
</span></span><span class="line"><span class="cl">255 heads, 63 sectors/track, 36351 cylinders
</span></span><span class="line"><span class="cl">Units = cylinders of 16065 * 512 = 8225280 bytes
</span></span><span class="line"><span class="cl">Sector size (logical/physical): 512 bytes / 4096 bytes
</span></span><span class="line"><span class="cl">I/O size (minimum/optimal): 4096 bytes / 4096 bytes
</span></span><span class="line"><span class="cl">Disk identifier: 0x00053169
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   Device Boot      Start         End      Blocks   Id  System
</span></span><span class="line"><span class="cl">/dev/sda1   *           1          26      204800   83  Linux
</span></span><span class="line"><span class="cl">Partition 1 does not end on cylinder boundary.
</span></span><span class="line"><span class="cl">/dev/sda2              26       36352   291785728   8e  Linux LVM
</span></span></code></pre></td></tr></table>
</div>
</div><p>可以看出sda这块磁盘：</p>
<ol>
<li>有 255 个heads(磁头)，也就是说共有255个盘面。</li>
<li>36351 个cylinders，也就是说每个盘面上都有36351个磁道，</li>
<li>63 sectors/track 说的是每个磁道上共有63个扇区。</li>
<li>逻辑扇区大小是512 bytes</li>
</ol>
<p>另外要知道，这些磁头数量，以及每个磁道上的扇区数量都是逻辑概念，为了编程方便虚拟出来的。实际上磁头数量很少，内磁道的扇区少，外磁道的扇区多。</p>
<h2 id="固态硬盘">固态硬盘</h2>
<p>SSD硬盘是基于NAND Flash存储技术的，属于非易失性存储设备，换成人话说，就是掉电了数据不会丢。</p>
<p><img src="/img/ssd_logic.png" alt=""></p>
<p>每个 Die 有若干个 Plane，每个 Plane 有若干个 Block，每个 Block 有若干个 Page。Page 是磁盘进行读写的最小单位，一般为2KB/4KB/8KB/16KB等。</p>
<p>另外为了兼容机械硬盘的 LBA 访问方式，SSD 也把物理 Page 分成了一个个 512 字节的逻辑扇区，当访问时，SSD控制器通过LBA MapTable 查找实际要访问的物理 Page。</p>
<h2 id="文件系统结构">文件系统结构</h2>
<p><img src="/img/filesystem_logic_desc.png" alt=""></p>
<h3 id="查看文件的基本存储单位-block-size">查看文件的基本存储单位 block size</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ stat -f .
</span></span><span class="line"><span class="cl">  File: &#34;.&#34;
</span></span><span class="line"><span class="cl">    ID: fd0000000000 Namelen: 255     Type: xfs
</span></span><span class="line"><span class="cl">Block size: 4096       Fundamental block size: 4096
</span></span><span class="line"><span class="cl">Blocks: Total: 7072385    Free: 4566651    Available: 4566651
</span></span><span class="line"><span class="cl">Inodes: Total: 14151680   Free: 13949831
</span></span></code></pre></td></tr></table>
</div>
</div><p>可以看到，Block size 是 4096 字节，一般文件系统的块大小也都是 1024、2048、4096 字节。这也意味着我们即使存储 1 个字节的文件，也是会占用磁盘的 4096 字节。</p>
<h3 id="查看文件系统的-inode">查看文件系统的 inode</h3>
<p>查看每个文件系统的 inode 数量，如下可以看到 inode 还剩很多。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ df -hTi
</span></span><span class="line"><span class="cl">Filesystem              Type     Inodes IUsed IFree IUse% Mounted on
</span></span><span class="line"><span class="cl">devtmpfs                devtmpfs   245K   391  245K    1% /dev
</span></span><span class="line"><span class="cl">tmpfs                   tmpfs      248K     1  248K    1% /dev/shm
</span></span><span class="line"><span class="cl">tmpfs                   tmpfs      248K   790  247K    1% /run
</span></span><span class="line"><span class="cl">tmpfs                   tmpfs      248K    16  248K    1% /sys/fs/cgroup
</span></span><span class="line"><span class="cl">/dev/mapper/centos-root xfs         14M  198K   14M    2% /
</span></span><span class="line"><span class="cl">/dev/sda1               xfs        512K   335  512K    1% /boot
</span></span><span class="line"><span class="cl">tmpfs                   tmpfs      248K     1  248K    1% /run/user/0
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="什么是硬链接">什么是硬链接</h3>
<p>一般情况下，文件名和inode号码是&quot;一一对应&quot;关系，每个inode号码对应一个文件名。但是，Unix/Linux 系统允许多个文件名指向同一个 inode 号码。</p>
<p>这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为&quot;硬链接&quot;（hard link）。</p>
<p>ln命令可以创建硬链接：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ ln 源文件 目标文件
</span></span></code></pre></td></tr></table>
</div>
</div><p>顺便说一下目录文件的&quot;链接数&quot;。创建目录时，默认会生成两个目录项：&quot;.&ldquo;和&rdquo;..&quot;。前者的inode号码就是当前目录的inode号码，等同于当前目录的&quot;硬链接&quot;；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的&quot;硬链接&quot;。所以，任何一个目录的&quot;硬链接&quot;总数，总是等于2加上它的子目录总数（含隐藏目录）。</p>
<h3 id="什么是软链接">什么是软链接</h3>
<p>除了硬链接以外，还有一种特殊情况。</p>
<p>文件 A 和文件 B 的 inode 号码虽然不一样，但是文件 A 的内容是文件 B 的路径。读取文件A时，系统会自动将访问者导向文件 B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的&quot;软链接&quot;（soft link）或者&quot;符号链接（symbolic link）。</p>
<p>这意味着，文件 A 依赖于文件 B 而存在，如果删除了文件 B，再打开文件 A 就会报错：&ldquo;No such file or directory&rdquo;。这是软链接与硬链接最大的不同：文件 A 指向文件 B 的文件名，而不是文件 B 的 inode 号码，文件B的 inode &ldquo;链接数&rdquo; 不会因此发生变化。</p>
<p>ln -s命令可以创建软链接。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ ln -s 源文文件或目录 目标文件或目录
</span></span></code></pre></td></tr></table>
</div>
</div><p>因为是只记录文件名的间接访问，所以可以跨文件系统创建软链接；</p>
<p>强制覆盖软链接（重新指向其它文件或目录）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ ln -sf 源文文件或目录 目标文件或目录
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="磁盘划分">磁盘划分</h2>
<p>不知道你有没有想过，Windows下的C、D、E、F盘是怎么划分磁盘空间的？</p>
<p>假设硬盘有50个盘面，3000个柱面。我们给出两种方案，你觉得哪个更好呢？</p>
<ul>
<li>方案一（按盘面）：50个盘面，C盘是0-10盘面， D盘是10-20个盘面,……</li>
<li>方案二（按柱面）：3000个柱面，C盘0-1000个柱面，D盘1000-2000个柱面,……</li>
</ul>
<p>要回答这个，还要从机械磁盘读写方式说起，可以分为三步：</p>
<ul>
<li>第一步，首先是磁头径向移动来寻找数据所在的磁道。这部分时间叫寻道时间。寻道时间，现代磁盘大概在3-15ms，其中寻道时间大小主要受磁头当前所在位置和目标磁道所在位置相对距离的影响。</li>
<li>第二步，找到目标磁道后通过盘面旋转，将目标扇区移动到磁头的正下方，这部分时间叫旋转延迟。现在主流服务器上经常使用的是1W转/分钟的磁盘，每旋转一周所需的时间为60*1000/10000=6ms，故其旋转延迟为（0-6ms）</li>
<li>第三步，向目标扇区读取或者写入数据，这部分时间叫存取时间。这个是电磁操作，所以一般耗时较短，为零点几ms。</li>
</ul>
<p>所以，单次磁盘IO时间 = 寻道时间 + 旋转延迟 + 存取时间。</p>
<p>假如采用第一种方案，那么磁头就需要在3000个磁道间不停地跳来跳去，这样磁盘的寻道时间就很高。而对于方案二，以磁盘 C 为例，只需要让磁头在1-1000个磁道间移动就可以了，能大大降低寻道时间。综合来看，肯定是方案二最优。</p>
<h2 id="冗余独立磁盘阵列raid">冗余独立磁盘阵列（RAID）</h2>
<ul>
<li>RAID0：至少需要两块硬盘，将硬盘组成一个大的卷组，各个硬盘单独存储数据，提高了数据的读出和写入速度，不能备份数据。</li>
<li>RAID1：将多块硬盘组成一个大的卷组，各个硬盘写入相同的数据，提高数据冗余安全，但是降低了硬盘的利用率，且成本高。</li>
<li>RAID5：RAID5是把硬盘设备的数据奇偶校验信息保存到其他的每一块硬盘，硬盘的数据如果损坏能够通过其他硬盘保存的数据奇偶校验信息对数据进行修复。</li>
<li>RAID10：RAID0和RAID1的组合体，至少需要四块硬盘，硬盘两两组成RAID1，提高数据冗余安全；然后两个RAID1组成RAID0提高数据读写速度。</li>
</ul>
<h1 id="文件访问的鉴权过程">文件访问的鉴权过程</h1>
<p>当我们找文件时，内核可以透过文件系统挂载信息找到挂载点根目录的 inode 号码，并依据该 inode 读取根目录的 block 内的目录名，再一层一层的往下读到正确的文件。举例来说，系统是如何读取 /etc/passwd 这个文件的呢？</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ ll -di / /etc /etc/passwd
</span></span><span class="line"><span class="cl">      128 dr-xr-x r-x . 17  root root 4096 May 4 17:56 /
</span></span><span class="line"><span class="cl"> 33595521 drwxr-x r-x . 131 root root 8192 Jun 17 00:20 /etc
</span></span><span class="line"><span class="cl"> 36628004 -rw-r-- r-- . 1   root root 2092 Jun 17 00:20 /etc/passwd
</span></span></code></pre></td></tr></table>
</div>
</div><p>上面是用 ls 命令查看访问路径，下面具体解释一下</p>
<ol>
<li>/ 根目录的 inode 透过挂载点的信息找到 inode 号码为 128，且 inode 的权限让我们可以读取该 block 的内容(有 r 和 x)；</li>
<li>/ 根目录的 block 经过上个步骤取得 block 号码，并找到该内容有 etc/ 目录的 inode 号码为 33595521；</li>
<li>etc/ 的 inode 信息里具有r 与x 的权限，因此可以读取 etc/ 的 block 内容；并在里面找到文件名为 passwd 的 inode 号码是 36628004；</li>
<li>读取 36628004 inode 得知我们具有 r 权限，因此可以读取 passwd 的block 内容；</li>
</ol>
<h1 id="浅析-linux-io-stack">浅析 Linux IO Stack</h1>
<p><img src="/img/file_io_stack.png" alt=""></p>
<h2 id="应用层">应用层</h2>
<p>标准 IO 的默认缓冲是全缓冲，一般是4096字节，但可以用 setvbuf 控制缓冲模式：</p>
<ul>
<li>_IOFBF（完全缓冲）当数据写满缓冲区时，才会执行真正的 write 系统调用；</li>
<li>_IOLBF（行缓冲）当数据写满缓冲区时，或者遇到换行符 \n 才会执行真正的 write 系统调用；</li>
<li>_IONBF（无缓存）每次写都会执行 write 系统调用。</li>
</ul>
<p>一个代码示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">FILE *pFile = fopen (&#34;myfile.txt&#34;,&#34;w&#34;); 
</span></span><span class="line"><span class="cl">setvbuf ( pFile , sBuf, _IOFBF , 1024 ); // 所以只有缓冲区满了（有1024字节），才往文件写入数据，可以减少IO次数
</span></span></code></pre></td></tr></table>
</div>
</div><p>标准 IO 的可以用 fflush 立即将缓冲区的内容刷新到操作系统的 Page Cache。</p>
<p>另外，我们执行系统调用 write 时，一般情况下都是写入操作系统 Page Cache 就返回了，如果想要写入磁盘成功后再返回，该怎么办呢？可以设置 open 打开的属性：</p>
<ul>
<li>O_DSYNC 每次 write 都等待物理I/O完成，不等待文件属性更新；</li>
<li>O_SYNC 每次 write 都等到物理I/O完成，包括 write 引起的文件属性的更新。</li>
</ul>
<p>也可以使用 sync、fsync、fdatasync 系统级API：</p>
<ul>
<li>void sync(void)：只是将所有修改过的块缓冲区放入写队列，然后就返回，它并不等待实际写磁盘操作结束。</li>
<li>int fsync(int fd)：把文件的内容和元数据都写入到磁盘中，等操作完成后才返回。</li>
<li>int fdatasync(fd)：只把文件的内容写入到磁盘中，等操作完成后才返回。当文件尺寸不变时，用 fdatasync 比 fsync 效率高（因为不需要更新文件的元信息），一般用于日志文件的追加。</li>
</ul>
<h2 id="虚拟文件系统层-vfs">虚拟文件系统层 VFS</h2>
<p>VFS 的思想就是在 Linux 上抽象一个通用的文件系统模型，对我们开发人员提供一组通用的接口，让我们不用关心具体文件系统的实现。VFS 定义了一系列的操作方法，比如 inode 的操作方法定义 inode_operations，在它的里面定义了我们非常熟悉的 mkdir 和 rename 等。对于 file 对象，定义了对应的操作方法 file_operations 如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">// include/linux/fs.h
</span></span><span class="line"><span class="cl">struct file {
</span></span><span class="line"><span class="cl">    ......
</span></span><span class="line"><span class="cl">    const struct file_operations    *f_op
</span></span><span class="line"><span class="cl">}
</span></span><span class="line"><span class="cl">struct file_operations {
</span></span><span class="line"><span class="cl">    ......
</span></span><span class="line"><span class="cl">    ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
</span></span><span class="line"><span class="cl">    ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
</span></span><span class="line"><span class="cl">            ......
</span></span><span class="line"><span class="cl">    int (*mmap) (struct file *, struct vm_area_struct *);
</span></span><span class="line"><span class="cl">    int (*open) (struct inode *, struct file *);
</span></span><span class="line"><span class="cl">    int (*flush) (struct file *, fl_owner_t id);
</span></span><span class="line"><span class="cl">}
</span></span></code></pre></td></tr></table>
</div>
</div><p>VFS 是抽象的，file_operations 里定义的 read、write 都只是函数指针，实际中需要由具体的文件系统来实现，例如 ext4、xfs 等等。</p>
<h2 id="page-cache">Page Cache</h2>
<p>当访问的文件时，如果文件的 block 正好存在于 Page Cache 内，那么 Page Cache 直接把数据从内核态拷贝到用户进程的内存中就可以了。如果不存在，那么会申请一个新页，然后用磁盘读取到的 block 内容来填充它 ，下次直接使用。</p>
<p>如果要访问的文件近期访问过，那么 Linux 大概率就是从 Page cache 内存中的拷贝给你，并不会有实际的磁盘 IO 发生。不过当设置了 DIRECT_IO 标志后，读写操作会绕过 Pagecache，因为这个标志意味着裸IO，直接操作磁盘设备文件。</p>
<p>当写文件返回时，也不是立即写入到磁盘，而是先写入 Page Cache，等待一个时机，异步刷回磁盘中。</p>
<h2 id="文件系统层">文件系统层</h2>
<p>Linux 下支持的文件系统有很多，常用的有 ext2/3/4、XFS、ZFS 等。</p>
<p>文件系统里提供对 VFS 的具体实现。除了数据结构，每个文件系统还会定义自己的实际操作函数。例如在 ext4 中定义的 ext4_file_operations。在其中包含了 VFS 中定义的 read 函数的具体实现：do_sync_read 和 do_sync_write。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">const struct file_operations ext4_file_operations = {
</span></span><span class="line"><span class="cl">    .llseek         = ext4_llseek,
</span></span><span class="line"><span class="cl">    .read           = do_sync_read,
</span></span><span class="line"><span class="cl">    .write          = do_sync_write,
</span></span><span class="line"><span class="cl">    .aio_read       = generic_file_aio_read,
</span></span><span class="line"><span class="cl">    .aio_write      = ext4_file_write,
</span></span><span class="line"><span class="cl">    ......
</span></span><span class="line"><span class="cl">}
</span></span></code></pre></td></tr></table>
</div>
</div><p>当 VFS 发现 Page Cache 里没有要找的数据时，就会执行具体文件系统的 read、write 操作。</p>
<h2 id="通用块管理层">通用块管理层</h2>
<p>文件系统还要依赖更下层的通用块层。</p>
<p>对上层的文件系统，通用块层提供一个统一的接口供实际的文件系统使用，而不用关心不同设备驱动程序的差异，这样实现出来的文件系统就能用于任何的块设备。通过对设备进行抽象后，不管是固态盘还是机械盘，对于文件系统都可以使用相同的接口对逻辑数据块进行读写操作。</p>
<p>对下层。I/O 请求添加到设备的 I/O 请求队列。它定义了一个叫 bio 的数据结构来表示一次 IO 操作请求。</p>
<h2 id="io-调度层">IO 调度层</h2>
<p>当通用块层把 IO 请求实际发出以后，并不一定会立即执行。因为调度层会从全局出发，尽量让整体磁盘 IO 性能最大化（排序、合并，随机转顺序）。</p>
<p>对于机械硬盘来说，调度层会尽量让磁头类似电梯那样工作，先往一个方向走，到头再回来，这样整体效率会比较高一些。具体的算法有 deadline 和 cfg，感兴趣可自行搜索。</p>
<p>对于固态硬盘来说，随机 IO 的问题已经被很大程度地解决了，所以可以直接使用最简单的 noop 调度器（也就是不调度）。</p>
<p>可以通过以下命令查看系统支持的 IO 调度算法：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ dmesg | grep -i scheduler
</span></span><span class="line"><span class="cl">[    1.112702] io scheduler noop registered
</span></span><span class="line"><span class="cl">[    1.112705] io scheduler deadline registered (default)
</span></span><span class="line"><span class="cl">[    1.112725] io scheduler cfq registered
</span></span><span class="line"><span class="cl">[    1.112727] io scheduler mq-deadline registered
</span></span><span class="line"><span class="cl">[    1.112729] io scheduler kyber registered
</span></span></code></pre></td></tr></table>
</div>
</div><p>接着就是把合并后的 IO 请求，交给硬件设备驱动程序负责具体的 DMA IO 操作。</p>
<h1 id="read-文件一个字节的io开销">read 文件一个字节的IO开销</h1>
<p>如果命中 Page Cache 的话，根本不会有磁盘 IO 产生。</p>
<p>如果没有命中 Page Cache，也会从 RAID（如果有的话） 缓存中查找，即使还没命中，现在的磁盘里本身就会带一块缓存。都没命中才会执行真正的设备 IO 操作。</p>
<p>那真正的设备 IO 操作，会读取多大呢？我们先看几个指标：</p>
<ul>
<li>Page Cache 是以页为单位的，Linux 页大小一般是 4KB；</li>
<li>文件系统是以块(block)为单位来管理的。使用 dumpe2fs 可以查看，一般一个块默认是 4KB；</li>
<li>通用块层是以段为单位来处理磁盘 IO 请求的，一个段为一个页或者是页的一部分；</li>
<li>IO 调度程序通过 DMA 方式传输 N 个扇区到内存，扇区一般为 512 字节（硬盘是采用“扇区”来管理和传输数据的）。</li>
</ul>
<p>所以，最底层的一次性读取单位是512字节，但系统会根据预读取策略和局部性原理，读取更多扇区，一般是大于等于4KB。</p>
<h1 id="write-文件一个字节的io开销">write 文件一个字节的IO开销</h1>
<p>其实大部分情况都是写入到 Page Cache 中就返回了，这时并没有真正写入磁盘。我们的数据会在下面三个时机被真正发起写磁盘IO请求：</p>
<ol>
<li>如果调用 write 时，发现 Page Cache 中脏页占比太多，超过了 dirty_ratio 或 dirty_bytes，write 就必须等待了。</li>
<li>write 写到 Page Cache 就已经返回了。worker 内核线程异步运行的时候，再次判断脏页占比，如果超过了 dirty_background_ratio 或 dirty_background_bytes，也发起写回请求。</li>
<li>同样 write 调用已经返回了。worker 内核线程异步运行的时候，虽然系统内脏页一直没有超过 dirty_background_ratio 或 dirty_background_bytes，但是脏页在内存中呆的时间超过了 dirty_expire_centisecs，也会发起会写。</li>
</ol>
<p>操作系统设计写入操作先到 Page Cache 的目的是为了高性能。但不保证写入数据的持久性。如果这时候断电，脏页还未刷回磁盘，那么数据就都丢失了。若要保证必须落盘，那么可以使用 sync、fsync、fdatasync 这类系统API。</p>
<h1 id="为什么有时候-ls-命令会卡住">为什么有时候 ls 命令会卡住？</h1>
<p>创建一个文件夹的资源消耗：</p>
<ul>
<li>首先要消耗掉一个inode，我的机器上它是256字节</li>
<li>需要消耗其父目录下的一个目录项 ext4_dir_entry_2，保存自己 inode、目录名。</li>
<li>其下面如果创建文件夹或者文件的话，就需要把他们存储在自己的 block 里的 ext4_dir_entry_2 数组里面。</li>
</ul>
<p>目录项的结构，以 EXT4 文件系统举例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">struct ext4_dir_entry_2 {
</span></span><span class="line"><span class="cl">        __le32  inode;                  /* Inode number */
</span></span><span class="line"><span class="cl">        __le16  rec_len;                /* Directory entry length */
</span></span><span class="line"><span class="cl">        __u8    name_len;               /* Name length */
</span></span><span class="line"><span class="cl">        __u8    file_type;
</span></span><span class="line"><span class="cl">        char    name[EXT4_NAME_LEN];    /* File name */
</span></span><span class="line"><span class="cl">};
</span></span></code></pre></td></tr></table>
</div>
</div><p>所以当目录下文件非常多的时候，会占用非常多的 block，存储非常多的目录项结构。当遍历文件夹的时候，如果Page Cache中没有命中要访问的 block，就会穿透到磁盘上进行实际的 IO。现象就是 ls 卡住了。</p>
<p>所以在我们编程的时候，如果要创建很多文件的话，一般的做法就是通过一级甚至是二级hash把文件散列到多个目录中，把单目录文件数量控制在 1万以下。</p>
<h1 id="查看分析磁盘性能问题">查看分析磁盘性能问题</h1>
<h2 id="系统级检查">系统级检查</h2>
<p>iostat 是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等常见的性能指标，这些指标实际上来自 /proc/diskstats。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"># -d -x表示显示所有磁盘I/O的指标
</span></span><span class="line"><span class="cl">$ iostat -d -x 1 
</span></span><span class="line"><span class="cl">Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util 
</span></span><span class="line"><span class="cl">loop0            0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00 
</span></span><span class="line"><span class="cl">loop1            0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00 
</span></span><span class="line"><span class="cl">sda              0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00 
</span></span><span class="line"><span class="cl">sdb              0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00 
</span></span></code></pre></td></tr></table>
</div>
</div><p>这些指标中，尤其关注三点：</p>
<ul>
<li>%util ，就是我们前面提到的磁盘 I/O 使用率；</li>
<li>r/s + w/s ，就是 IOPS；单独指标含义是合并后的读、写请求数量；</li>
<li>rkB/s + wkB/s ，就是吞吐量。单独指标含义就是每秒从磁盘读取、写入的 KB 数量。</li>
</ul>
<h2 id="进程级检查">进程级检查</h2>
<p>pidstat 给它加上 -d 参数，就可以看到进程的 I/O 情况，如下所示：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">$ pidstat -d 1 
</span></span><span class="line"><span class="cl">13:39:51      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command 
</span></span><span class="line"><span class="cl">13:39:52      102       916      0.00      4.00      0.00       0  rsyslogd
</span></span></code></pre></td></tr></table>
</div>
</div><p>列出了每个进程的 I/O 情况，包括下面这些内容。</p>
<ul>
<li>用户 ID（UID）和进程 ID（PID） 。</li>
<li>每秒读取的数据大小（kB_rd/s） ，单位是 KB。</li>
<li>每秒发出的写请求数据大小（kB_wr/s） ，单位是 KB。</li>
<li>每秒取消的写请求数据大小（kB_ccwr/s） ，单位是 KB。</li>
</ul>
<h1 id="磁盘-io-优化建议">磁盘 IO 优化建议</h1>
<p>首先判断应用程序的类型，是顺序读写那种（吞吐量优先），还是需要随机读写（IOPS优先）。</p>
<p>不过总体来说，还是以下几种思路：</p>
<ul>
<li>用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。系统日志的 WAL 设计，就是遵循这种原理进行优化的思想，速度很快；</li>
<li>可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统。这样，一方面，能在应用程序内部，控制缓存的数据和生命周期；另一方面，也能降低其他应用程序使用缓存对自身的影响；</li>
<li>在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC；</li>
<li>在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量；</li>
<li>可以优化 pdflush 脏页的刷新频率（比如设置 dirty_expire_centisecs 和 dirty_writeback_centisecs）以及脏页的限额（比如调整 dirty_background_ratio 和 dirty_ratio 等）；</li>
<li>还可以优化内核回收目录项缓存和索引节点缓存的倾向，即调整 vfs_cache_pressure（/proc/sys/vm/vfs_cache_pressure，默认值 100），数值越大，就表示越容易回收；</li>
<li>在不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半；</li>
<li>换更快的硬盘，HDD 换 SSD。</li>
</ul>

    </div>

    
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E8%B0%83%E4%BC%98-memory/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">性能分析调优 - Memory</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/%E6%BC%AB%E8%B0%88%E5%85%B1%E8%AF%86%E5%8D%8F%E8%AE%AE-paxos/">
            <span class="next-text nav-default">漫谈共识协议 - paxos</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="http://blog.gongchang.me/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span>olOwOlo</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script><script></script><script src="https://cdn.jsdelivr.net/npm/raphael@2.2.7/raphael.min.js" integrity="sha256-67By+NpOtm9ka1R6xpUefeGOY8kWWHHRAKlvaTJ7ONI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/flowchart.js@1.8.0/release/flowchart.min.js" integrity="sha256-zNGWjubXoY6rb5MnmpBNefO0RgoVYfle9p0tvOQM+6k=" crossorigin="anonymous"></script><script></script><script src="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.js" integrity="sha256-4O4pS1SH31ZqrSO2A/2QJTVjTPqVe+jnYgOWUVr7EEc=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/snapsvg@0.5.1/dist/snap.svg-min.js" integrity="sha256-oI+elz+sIm+jpn8F/qEspKoKveTc5uKeFHNNVexe6d8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/underscore@1.8.3/underscore-min.js" integrity="sha256-obZACiHd7gkOk9iIL/pimWMTJ4W/pBsKu+oZnSeBIek=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/gh/bramp/js-sequence-diagrams@2.0.1/dist/sequence-diagram-min.js" integrity="sha384-8748Vn52gHJYJI0XEuPB2QlPVNUkJlJn9tHqKec6J3q2r9l8fvRxrgn/E5ZHV0sP" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/bramp/js-sequence-diagrams@2.0.1/dist/sequence-diagram-min.css" integrity="sha384-6QbLKJMz5dS3adWSeINZe74uSydBGFbnzaAYmp+tKyq60S7H2p6V7g1TysM5lAaF" crossorigin="anonymous">



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>








</body>
</html>
